---
title: "Project 2"
author: "Taimur Hassan, th29448"
date: "5/4/2020"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, fig.align = "center", warning = F, message = F,
tidy=TRUE, tidy.opts=list(width.cutoff=60), R.options=list(max.print=100))
```

```{r}
#Data Sets
library(nlme)
library(tidyverse)
MathAchSchool-> MathAchSchool2
head(MathAchSchool2)
```


The dataset in question is that of a school demographic data. There are 7 variables. The School variable is a numeric variable used as an ID. Size is another numeric variable giving the number of students in each school. Sector is a categorical variable with two levels: Public and Catholic. PRACAD is a numeric variable givign the percentage of students on the academic track. DISCLIM is another numeric variable measuring the discrimination climate in each school. HIMINTY is a binary variable with values of 0 and 1, where 1 has a school enrollment of 40% minority, while 0 has a school enrollment of less than and equal to 40% minority. MEANSES is a numeric variable giving the mean SES score of the school. The number of observations are 160 in total.


```{r}
#MANOVA
manmath<-manova(cbind(PRACAD,DISCLIM,Size)~Sector,data=MathAchSchool2)
summary(manmath)
summary.aov(manmath)
summary(aov(cbind(PRACAD,DISCLIM,Size)~Sector,data=MathAchSchool2))
pairwise.t.test(MathAchSchool2$PRACAD,MathAchSchool2$Sector,p.adj="none")
pairwise.t.test(MathAchSchool2$DISCLIM,MathAchSchool2$Sector,p.adj="none")
pairwise.t.test(MathAchSchool2$Size,MathAchSchool2$Sector,p.adj="none")
0.05/7 
```
The numeric variables, PRACAD, DISCLIM, and Size, do show a mean difference across levels of the categorical variable, Sector. Univariate ANOVAs do show a mean difference across groups for all three numeric variables. All three DISCLIM, PRACAD, and Size differ in Public and Catholic Sector of schools. In totality, 7 tests were done (1 MANOVA, 3 ANOVAs, 3 t-tests). After the bonferroni correctino, the signficance level is adjusted to 0.007142857. Significant differencs were found among the Sectors for at least one of the dependent variables. Univariate ANOVAs for each dependent variable were conducted as follow-up tests to the MANOVA, using the Bonferroni method for controlling Type I error rates. The Univariate ANOVAs for PRACAD, DISCLIM, and Size were all significant, F = 130.38, p < .0001, F = 162.89 p =< .0001, F= 40.541, p<0.001, respectively. Both sectors differed significantly from each other in terms of PRACAD, DISCLIM, and Size after post hoc tests. MANOVA has many assumptions, including multivariate normal distribution, all groups have same variance/covariance, sensitivity to multicollinearity, needing more samples than variables, being highly sensitive to many 0s (outliers). It can be deciphered that most assumptions have been met except that of the data having outliers. It is also to be noted that the data might not have a perfectly normal disribution. 

```{R}
#Randomization Test:
set.seed(348)
rand_dist<-vector()
for(i in 1:5000){
new<-data.frame(DISCLIM=sample(MathAchSchool2$DISCLIM),Sector=MathAchSchool2$Sector) 
rand_dist[i]<-mean(new[new$Sector=="Catholic",]$DISCLIM)-
              mean(new[new$Sector=="Public",]$DISCLIM)}
MathAchSchool2%>%group_by(Sector)%>%
  summarize(means=mean(DISCLIM))%>%summarize(`mean_diff:`=diff(means))
hist(rand_dist)
{hist(rand_dist,main="",ylab=""); abline(v = 1.398762,col="red")}
mean(rand_dist< -1.398762 | rand_dist > 1.398762)

```
Null Hypothesis is that there is no difference in DISCLIM between the Catholic and Public Sectors. Alternative Hypothesis is that there is a difference in DISCLIM between the two sectors. The means of DISCLIM for both sectors are not as extreme as 1.398762. It would be highly unlikely to get a mean difference this big if the outcome data is splitted. The test statistic is too large to fit into the graph of the null distribution.


```{R}
#Regression Model
install.packages('lmtest', repos = "http://cran.us.r-project.org")
install.packages('sandwich', repos = "http://cran.us.r-project.org")
install.packages('plotly', repos = "http://cran.us.r-project.org")
library(lmtest)
library(MASS)
library(sandwich)
library(tidyverse)
library(dplyr)
library(plotly)
MathAchSchool2$PRACAD_c <- MathAchSchool2$PRACAD - mean(MathAchSchool2$PRACAD)
MathAchSchool2$DISCLIM_c <- MathAchSchool2$DISCLIM - mean(MathAchSchool2$DISCLIM)
fit<-lm(PRACAD_c ~ DISCLIM_c*Sector, data=MathAchSchool2)
summary(fit)
library(ggplot2)
MathAchSchool2%>%ggplot(aes(x = DISCLIM, y = PRACAD, color = Sector)) +
stat_smooth(method = "lm", se = FALSE, fullrange = TRUE)
resids<-fit$residuals
fitvals<-fit$fitted.values
ggplot()+geom_point(aes(fitvals,resids))+geom_hline(yintercept=0, color='red')
ks.test(resids, "pnorm", mean=0, sd(resids))
bptest(fit)
coeftest(fit, vcov = vcovHC(fit))


```
Controlling for Sector, there is not a significant effect of DISCLIM_c on PRACAD_C. For every one unit increase in DISCLIM_c, PRACAD_c decreases by 0.035. However, after
controlling for DISCLIM_c, there is a difference in PRACAD between Catholic and Public Schools. For every one unit increase in Sector, PRACAD_c increases by 0.21.  (t for DISCLIM_c = -1.3741, df = 153, p > .001, t for Sector = 4.2055, p <0.01)

The data obtained is linear. The Kolmogorov-Smirnov test shows that the data is normal. The Breusch-Pagan test shows that the data is homoskedastic as the Breusch-Pagan test shows. 
After regression with robust standard errors, controlling for Sector, there is not a significant effect of DISCLIM_c on PRACAD_C. For every one unit increase in DISCLIM_c, PRACAD_c decreases by 0.035. However, after controlling for DISCLIM_c, there is a difference in PRACAD between Catholic and Public Schools. There were no changes before/after the application of robust SEs.

50.66% of the variation is explained by the model (all predictors at once). 49.71% of the variation in the outcome is explained by the model but with penalty for each extra explanatory variable (adjusted R squared).


```{r}
#Bootstrapping
boot_dat<- sample_frac(MathAchSchool2, replace=T)
#repeat 5000 times
samp_distn<-replicate(5000, {
boot_dat <- sample_frac(MathAchSchool2, replace=T) 
fit<-lm(PRACAD_c ~ DISCLIM_c*Sector, data=boot_dat)
coef(fit)
})
samp_distn %>% t %>% as.data.frame %>% summarize_all(sd)
```

There are no significant changes in any SEs in the bootstrapped model compared to the original or robust model. In fact, the bootstrapped standard errors are more similar to the robust standard error (the intercept is almost the same, and DISCLIM_c, Sector and the interaction has similar standard error in both). In essence, there standard errors are to be very similar so as to not change the p-value much (p-values almost remain the same). 

```{r}
#Logistic Regression
fitl<-glm(HIMINTY~DISCLIM+MEANSES, data=MathAchSchool2, family="binomial")
coeftest(fitl)
exp(coef(fitl))
prob<-predict(fitl,type="response")
pred<-ifelse(prob>.5,1,0)
table(prediction=pred, truth=MathAchSchool2$HIMINTY)%>%addmargins
(112+17)/160 #Accuracy
17/44 #TPR
112/116 #TNR
17/21 #PPV
probs<-predict(fitl,type="response")
MathAchSchool2$logit<-predict(fitl,type="link") #get log-odds for everyone
## Density plot of log-odds for each outcome:
MathAchSchool2%>%ggplot()+geom_density(aes(logit,color=HIMINTY,fill=HIMINTY), alpha=.4)+
  theme(legend.position=c(.85,.85))+geom_vline(xintercept=0)+xlab("logit (log-odds)")+
  geom_rug(aes(logit,color=HIMINTY))+
  geom_text(x=-5,y=.07,label="TN = 112")+
  geom_text(x=-1.75,y=.008,label="FN = 27")+
  geom_text(x=1,y=.006,label="FP = 4")+
  geom_text(x=5,y=.04,label="TP = 17")
install.packages('plotROC', repos = "http://cran.us.r-project.org")
library(plotROC) 
ROCplot<-ggplot(MathAchSchool2)+geom_roc(aes(d=HIMINTY,m=prob), n.cuts=0)+
geom_segment(aes(x=0,xend=1,y=0,yend=1),lty=2)
ROCplot
calc_auc(ROCplot)

class_diag<-function(probs,truth){
  
  tab<-table(factor(probs>.5,levels=c("FALSE","TRUE")),truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]

  if(is.numeric(truth)==FALSE & is.logical(truth)==FALSE) truth<-as.numeric(truth)-1
  
  #CALCULATE EXACT AUC
  ord<-order(probs, decreasing=TRUE)
  probs <- probs[ord]; truth <- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup<-c(probs[-1]>=probs[-length(probs)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,auc)
}

MathAchSchool2$HIMINTY = as.factor(MathAchSchool2$HIMINTY)

set.seed(1234)
k=10 

data<-MathAchSchool2[sample(nrow(MathAchSchool2)),] 
folds<-cut(seq(1:nrow(MathAchSchool2)),breaks=k,labels=F) 
diags<-NULL
for(i in 1:k){

  train<-data[folds!=i,] 
  test<-data[folds==i,]
  truth<-test$HIMINTY

 fit<-glm(HIMINTY~DISCLIM+MEANSES, data=train, family="binomial")
  probs<-predict(fit,newdata = test,type="response")
  

  diags<-rbind(diags,class_diag(probs,truth))
}


summarize_all(diags,mean) 
```

Cotrolling for MEANSES, there is not a significant effect of DISCLIM on HIMINTY. For every one unit increase in DISCLIM, the odds of HIMINTY change by a factor of 0.7528. Controlling for DISCLIM, there is a significant effect of MEANSES on HIMINTY. For every one unit increase in MEANSES, the odds of HIMINTY change by a factor of 0.066. The Recall is 0.8095.

The Accuracy is 0.806 which is good. Sensitivity and Specificity are 0.386 and 0.966. Sensitivity is somewhat low.


The ROC curve is not bad but could have been better. The AUC is 0.744 which lies in the category of being fair. 

After 10-fold CV, the Accuracy is 0.806. Sensitivity is 0.424, and Recall is 0.8333.


```{r}
#Lasso Regression
install.packages('glmnet', repos = "http://cran.us.r-project.org")
library(glmnet)
MathAchSchool2$HIMINTY = as.numeric(MathAchSchool2$HIMINTY) 
y<-as.matrix(MathAchSchool2$HIMINTY)
x<-model.matrix(HIMINTY~Size+Sector+PRACAD+DISCLIM+MEANSES,data=MathAchSchool2)[,-1]  
head(x)
#cannot include the variable school as it is an ID

cv <- cv.glmnet(x,y) 

{plot(cv$glmnet.fit, "lambda", label=TRUE); abline(v = log(cv$lambda.1se)); abline(v = log(cv$lambda.min),lty=2)}

cv<-cv.glmnet(x,y,family="binomial")
lasso<-glmnet(x,y,family="binomial",lambda=cv$lambda.1se)
coef(lasso)
```

```{r}
set.seed(1234)
k=10 
MathAchSchool2$HIMINTY = factor(MathAchSchool2$HIMINTY) 

data<-MathAchSchool2[sample(nrow(MathAchSchool2)),] 
folds<-cut(seq(1:nrow(MathAchSchool2)),breaks=k,labels=F) 

diags<-NULL
for(i in 1:k){

  train<-data[folds!=i,] 
  test<-data[folds==i,]
  truth<-test$HIMINTY
  

 fit<-glm(HIMINTY~MEANSES, data=train, family="binomial")
  probs<-predict(fit,newdata = test,type="response")
  

  diags<-rbind(diags,class_diag(probs,truth))
}


summarize_all(diags,mean)


```

MEANSES variable is retained after lasso regression as it gives a numeric value.
 
Compared to the Logistic Regression done previously , surprisingly, the accuracy gets lower by approximately 0.01. Everything gets very slightly lower except the AUC which gets slightly higher. Overall, there is very little change.
```{R}